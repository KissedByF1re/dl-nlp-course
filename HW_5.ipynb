{"cells":[{"cell_type":"markdown","id":"5bad348a","metadata":{"id":"5bad348a"},"source":["### Домашнее задание 5 - 10 баллов\n","\n","В этом задании вам предстоит дообучить трансформерную модель для задачи классификации с помощью различных техник и сравнить их между собой.\n","\n","Датасет: [dair-ai/emotion](https://huggingface.co/datasets/dair-ai/emotion)\n","\n","Модель: [google-bert/bert-base-uncased](https://huggingface.co/google-bert/bert-base-uncased) (если хочется, можно заменить на что-то более интересное)\n","\n","1. Скачайте датасет и модель. Измерьте базовые метрики классификации перед началом экспериментов.\n","\n","**NB!** Для всех типов дообучения замерьте :\n","- качество классификации на выходе\n","- время дообучения\n","- количество параметров для обучения\n","- потребление ресурсов (не нужно заморачиваться с профайлингом - можно просто посмотреть в `nvidia-smi` или `torch.cuda.memory_allocated`)\n","\n","2. Обучите модель в режиме full finetuning - **1 балл**\n","3. Обучите модель в режиме linear probing - реализуйте кастомную классификационную голову и обучайте только ее. Не забудьте описать, чем обусловлено устройство головы, как вы пришли к такой архитектуре - **2 балла**\n","4. Обучите модель в режиме PEFT с использованием [prompt tuning или prefix tuning](https://ericwiener.github.io/ai-notes/AI-Notes/Large-Language-Models/Prompt-Tuning-and-Prefix-Tuning). При выборе метода напишите пару слов, почему решили остановиться именно на этом методе - **2 балла**\n","4. Обучите модель в режиме PEFT с использованием LoRA. Попробуйте подобрать оптимальный ранг - `r`, при желании поэкспериментируйте с остальными гиперпараметрами. Опишите, чем обусловлена ваша финальная конфигурация - **2 балла**\n","\n","5. Соберите все результаты отдельных замеров в таблицу и сделайте выводы о вычислительной сложности методов, итоговом качестве и прочих наблюдаемых свойствах моделей - **1 балл**\n","\n","**Задание выполнено в Google Colab**"]},{"cell_type":"code","source":["!pip install evaluate"],"metadata":{"id":"UZb-LGduTY0k"},"id":"UZb-LGduTY0k","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":3,"id":"855f1099","metadata":{"id":"855f1099","executionInfo":{"status":"ok","timestamp":1746177821049,"user_tz":-180,"elapsed":23250,"user":{"displayName":"Константин Розанов","userId":"17140738066365642382"}}},"outputs":[],"source":["import torch\n","import numpy as np\n","import random\n","import evaluate\n","import time\n","import pandas as pd\n","\n","from datasets import load_dataset\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n","from peft import get_peft_model, LoraConfig, TaskType, PromptTuningConfig\n","from transformers import DataCollatorWithPadding"]},{"cell_type":"code","source":["# Обеспечим воспроизводимость\n","SEED = 42\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed_all(SEED)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"uZlKA2BsTbDk","executionInfo":{"status":"ok","timestamp":1746177878201,"user_tz":-180,"elapsed":68,"user":{"displayName":"Константин Розанов","userId":"17140738066365642382"}}},"id":"uZlKA2BsTbDk","execution_count":4,"outputs":[]},{"cell_type":"markdown","id":"9c80f1d8","metadata":{"id":"9c80f1d8"},"source":["**1. Загрузка данных и модели**"]},{"cell_type":"code","execution_count":null,"id":"38ec8b07","metadata":{"id":"38ec8b07"},"outputs":[],"source":["dataset = load_dataset(\"dair-ai/emotion\")\n","label_list = dataset[\"train\"].features[\"label\"].names\n","num_labels = len(label_list)\n","\n","model_name = \"bert-base-uncased\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","def tokenize(example):\n","    return tokenizer(example[\"text\"], truncation=True)\n","\n","dataset = dataset.map(tokenize, batched=True)\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"]},{"cell_type":"code","execution_count":6,"id":"6bc557e2","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":272},"id":"6bc557e2","executionInfo":{"status":"ok","timestamp":1746177921479,"user_tz":-180,"elapsed":70,"user":{"displayName":"Константин Розанов","userId":"17140738066365642382"}},"outputId":"355eacfa-ee48-4b99-cd08-a078471da530"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    5362\n","0    4666\n","3    2159\n","4    1937\n","2    1304\n","5     572\n","Name: count, dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>5362</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>4666</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2159</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1937</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1304</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>572</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{},"execution_count":6}],"source":["pd.Series(dataset[\"train\"][\"label\"]).value_counts()"]},{"cell_type":"markdown","source":["В коллабе есть ограничение на время использование GPU, поэтому не будем трогать количество эпох и learning rate. Будем смотреть сходимость за фиксированное количество эпох. А для оценки метрик в конце используется лучшая модель среди всех эпох по минимальному валидационному лоссу"],"metadata":{"id":"scEJDHhRUKgq"},"id":"scEJDHhRUKgq"},{"cell_type":"code","execution_count":7,"id":"964140b3","metadata":{"id":"964140b3","executionInfo":{"status":"ok","timestamp":1746178257608,"user_tz":-180,"elapsed":126,"user":{"displayName":"Константин Розанов","userId":"17140738066365642382"}}},"outputs":[],"source":["args = TrainingArguments(\n","    output_dir=\"/content/hw_5\",\n","    eval_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=64,\n","    num_train_epochs=10,\n","    learning_rate=1e-4,\n","    seed=SEED,\n","    load_best_model_at_end=True,\n",")"]},{"cell_type":"code","execution_count":null,"id":"21f8ed03","metadata":{"id":"21f8ed03"},"outputs":[],"source":["model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels).to(device)\n","\n","accuracy_metric = evaluate.load(\"accuracy\")\n","recall_metric = evaluate.load(\"recall\")\n","precision_metric = evaluate.load(\"precision\")\n","f1_metric = evaluate.load(\"f1\")\n","\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    return {\n","        \"Accuracy\": accuracy_metric.compute(predictions=predictions, references=labels)[\"accuracy\"],\n","        \"Recall\": recall_metric.compute(predictions=predictions, references=labels, average=\"macro\", zero_division=0)[\n","            \"recall\"\n","        ],\n","        \"Precision\": precision_metric.compute(\n","            predictions=predictions, references=labels, average=\"macro\", zero_division=0\n","        )[\"precision\"],\n","        \"F1\": f1_metric.compute(predictions=predictions, references=labels, average=\"macro\")[\"f1\"],\n","    }\n","\n","trainer = Trainer(\n","    model=model,\n","    args=args,\n","    train_dataset=dataset[\"train\"],\n","    eval_dataset=dataset[\"validation\"],\n","    processing_class=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"code","execution_count":10,"id":"56ca0d0b","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":228},"id":"56ca0d0b","executionInfo":{"status":"ok","timestamp":1746178488551,"user_tz":-180,"elapsed":5679,"user":{"displayName":"Константин Розанов","userId":"17140738066365642382"}},"outputId":"b8ec6e71-7884-47de-e57f-84297324476f"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='64' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [32/32 03:23]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["eval_loss: 1.6840\n","eval_model_preparation_time: 0.0030\n","eval_Accuracy: 0.1510\n","eval_Recall: 0.1619\n","eval_Precision: 0.1449\n","eval_F1: 0.0729\n","eval_runtime: 5.6283\n","eval_samples_per_second: 355.3460\n","eval_steps_per_second: 5.6860\n","Trainable parameters: 109.49, M\n","CUDA memory used: 447.61MB\n"]}],"source":["eval_results = trainer.evaluate(dataset[\"test\"])\n","for metric, value in eval_results.items():\n","    print(f\"{metric}: {value:.4f}\")\n","print(f\"Trainable parameters: {(sum(p.numel() for p in model.parameters() if p.requires_grad) / 1e6):.2f}, M\")\n","print(f\"CUDA memory used: {(torch.cuda.memory_allocated() / 1e6):.2f}MB\")"]},{"cell_type":"code","execution_count":13,"id":"a893b096","metadata":{"id":"a893b096","executionInfo":{"status":"ok","timestamp":1746178628462,"user_tz":-180,"elapsed":29,"user":{"displayName":"Константин Розанов","userId":"17140738066365642382"}}},"outputs":[],"source":["def train_and_show_results(trainer):\n","    start = time.time()\n","    trainer.train()\n","    end = time.time()\n","\n","    eval_results = trainer.evaluate(dataset[\"test\"])\n","    for metric, value in eval_results.items():\n","        print(f\"{metric}: {value:.4f}\")\n","    print(\"Training time:\", round(end - start, 2), \"sec\")\n","    print(f\"Trainable parameters: {(sum(p.numel() for p in trainer.model.parameters() if p.requires_grad) / 1e6):.2f}M\")\n","    print(f\"CUDA memory used: {(torch.cuda.memory_allocated() / 1e6):.2f}MB\")"]},{"cell_type":"markdown","id":"87630133","metadata":{"id":"87630133"},"source":["**2. Full finetuning**"]},{"cell_type":"code","execution_count":14,"id":"d1a40d9f","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":654},"id":"d1a40d9f","executionInfo":{"status":"ok","timestamp":1746180421275,"user_tz":-180,"elapsed":1789875,"user":{"displayName":"Константин Розанов","userId":"17140738066365642382"}},"outputId":"98eacf67-a344-4733-b6d7-bdd7b7d9f789"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [10000/10000 29:41, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Model Preparation Time</th>\n","      <th>Accuracy</th>\n","      <th>Recall</th>\n","      <th>Precision</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.303500</td>\n","      <td>0.241592</td>\n","      <td>0.003000</td>\n","      <td>0.920000</td>\n","      <td>0.913736</td>\n","      <td>0.880857</td>\n","      <td>0.894471</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.216900</td>\n","      <td>0.210723</td>\n","      <td>0.003000</td>\n","      <td>0.933500</td>\n","      <td>0.892222</td>\n","      <td>0.931130</td>\n","      <td>0.907770</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.168100</td>\n","      <td>0.233989</td>\n","      <td>0.003000</td>\n","      <td>0.926500</td>\n","      <td>0.904639</td>\n","      <td>0.905898</td>\n","      <td>0.901467</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.141400</td>\n","      <td>0.267452</td>\n","      <td>0.003000</td>\n","      <td>0.930500</td>\n","      <td>0.903833</td>\n","      <td>0.903611</td>\n","      <td>0.903173</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.105300</td>\n","      <td>0.370138</td>\n","      <td>0.003000</td>\n","      <td>0.924000</td>\n","      <td>0.910869</td>\n","      <td>0.889622</td>\n","      <td>0.898964</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.073900</td>\n","      <td>0.381330</td>\n","      <td>0.003000</td>\n","      <td>0.931000</td>\n","      <td>0.899350</td>\n","      <td>0.908406</td>\n","      <td>0.903760</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.039000</td>\n","      <td>0.425138</td>\n","      <td>0.003000</td>\n","      <td>0.930500</td>\n","      <td>0.897094</td>\n","      <td>0.913173</td>\n","      <td>0.904842</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.027300</td>\n","      <td>0.393160</td>\n","      <td>0.003000</td>\n","      <td>0.933500</td>\n","      <td>0.907258</td>\n","      <td>0.904395</td>\n","      <td>0.905700</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.016600</td>\n","      <td>0.468375</td>\n","      <td>0.003000</td>\n","      <td>0.933500</td>\n","      <td>0.911238</td>\n","      <td>0.905388</td>\n","      <td>0.907803</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.010400</td>\n","      <td>0.482386</td>\n","      <td>0.003000</td>\n","      <td>0.932000</td>\n","      <td>0.907905</td>\n","      <td>0.903346</td>\n","      <td>0.905400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='96' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [32/32 08:33]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [32/32 00:06]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["eval_loss: 0.2020\n","eval_model_preparation_time: 0.0030\n","eval_Accuracy: 0.9265\n","eval_Recall: 0.8639\n","eval_Precision: 0.9136\n","eval_F1: 0.8830\n","eval_runtime: 6.5028\n","eval_samples_per_second: 307.5590\n","eval_steps_per_second: 4.9210\n","epoch: 10.0000\n","Training time: 1783.31 sec\n","Trainable parameters: 109.49M\n","CUDA memory used: 1333.99MB\n"]}],"source":["train_and_show_results(trainer)"]},{"cell_type":"markdown","id":"93bd080d","metadata":{"id":"93bd080d"},"source":["**3. Linear probing**"]},{"cell_type":"markdown","source":["Загружаем модель и замораживаем Encoder, чтобы обучалась только голова. Здесь используется:\n","- CLS токен → Dropout → Dense → Softmax\n","\n","Это простой и эффективный классификатор, не требовательный по ресурсам + класс уже реализован в transformers\n"],"metadata":{"id":"Dp5hMjBfW-OT"},"id":"Dp5hMjBfW-OT"},{"cell_type":"code","execution_count":15,"id":"f3515e1d","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":672},"id":"f3515e1d","executionInfo":{"status":"ok","timestamp":1746181044622,"user_tz":-180,"elapsed":609351,"user":{"displayName":"Константин Розанов","userId":"17140738066365642382"}},"outputId":"efb1b44b-8b6d-4a27-f253-22ade65b9e44"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [10000/10000 09:59, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Recall</th>\n","      <th>Precision</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.560000</td>\n","      <td>1.546992</td>\n","      <td>0.427500</td>\n","      <td>0.223030</td>\n","      <td>0.140630</td>\n","      <td>0.172138</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.532200</td>\n","      <td>1.519435</td>\n","      <td>0.427500</td>\n","      <td>0.218589</td>\n","      <td>0.143581</td>\n","      <td>0.168333</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>1.516400</td>\n","      <td>1.507072</td>\n","      <td>0.450500</td>\n","      <td>0.231203</td>\n","      <td>0.151246</td>\n","      <td>0.178556</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>1.500000</td>\n","      <td>1.500926</td>\n","      <td>0.454000</td>\n","      <td>0.242405</td>\n","      <td>0.153779</td>\n","      <td>0.186170</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>1.492600</td>\n","      <td>1.478775</td>\n","      <td>0.468500</td>\n","      <td>0.242642</td>\n","      <td>0.155058</td>\n","      <td>0.187503</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>1.483100</td>\n","      <td>1.481191</td>\n","      <td>0.465500</td>\n","      <td>0.248182</td>\n","      <td>0.156873</td>\n","      <td>0.190619</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>1.480500</td>\n","      <td>1.468469</td>\n","      <td>0.474500</td>\n","      <td>0.246809</td>\n","      <td>0.156574</td>\n","      <td>0.190684</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>1.473000</td>\n","      <td>1.465585</td>\n","      <td>0.477000</td>\n","      <td>0.249848</td>\n","      <td>0.156922</td>\n","      <td>0.192717</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>1.476800</td>\n","      <td>1.464318</td>\n","      <td>0.478500</td>\n","      <td>0.250227</td>\n","      <td>0.157362</td>\n","      <td>0.193068</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>1.474800</td>\n","      <td>1.462060</td>\n","      <td>0.480500</td>\n","      <td>0.251108</td>\n","      <td>0.158095</td>\n","      <td>0.193804</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [32/32 00:06]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["eval_loss: 1.4335\n","eval_Accuracy: 0.4640\n","eval_Recall: 0.2389\n","eval_Precision: 0.1531\n","eval_F1: 0.1860\n","eval_runtime: 6.5645\n","eval_samples_per_second: 304.6670\n","eval_steps_per_second: 4.8750\n","epoch: 10.0000\n","Training time: 600.46 sec\n","Trainable parameters: 0.00M\n","CUDA memory used: 895.94MB\n"]}],"source":["lp_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n","\n","for param in lp_model.bert.parameters():\n","    param.requires_grad = False\n","\n","lp_model = lp_model.to(device)\n","\n","trainer = Trainer(\n","    model=lp_model,\n","    args=args,\n","    train_dataset=dataset[\"train\"],\n","    eval_dataset=dataset[\"validation\"],\n","    processing_class=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n",")\n","\n","train_and_show_results(trainer)"]},{"cell_type":"markdown","id":"f8a6c38d","metadata":{"id":"f8a6c38d"},"source":["**4. Prompt/Prefix tuning**"]},{"cell_type":"markdown","source":["Метод **Prefix tuning** звучит интереснее, так как в нем добавляются обучаемые векторы прямо в attention, а не просто в начало текста. А значит влияние этих токенов по логике должно быть сильнее, что может быть довольно полезно в задачах, подобных этой. Такой подход немного тяжелее по памяти + лучше работает на моделях типа BERT.\n","\n","Однако я буду использовать **Prompt Tuning**, так как он позволяет дообучать небольшое количество виртуальных токенов, которые добавляются в начало входа, а это крутой способ, особенно если нет возможности гонять всю модель. Дополнительной фичей является то, что его легко внедрить через готовые инструменты и он не требует изменений внутри самой модели."],"metadata":{"id":"kMvovviBZ2V0"},"id":"kMvovviBZ2V0"},{"cell_type":"code","execution_count":17,"id":"12ca67b9","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":706},"id":"12ca67b9","executionInfo":{"status":"ok","timestamp":1746182603630,"user_tz":-180,"elapsed":1449974,"user":{"displayName":"Константин Розанов","userId":"17140738066365642382"}},"outputId":"ddc65862-20ea-4a13-dc2b-4e6447bc4af9"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["trainable params: 15,360 || all params: 109,502,214 || trainable%: 0.0140\n"]},{"output_type":"stream","name":"stderr","text":["No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [10000/10000 23:57, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Recall</th>\n","      <th>Precision</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.611700</td>\n","      <td>1.591554</td>\n","      <td>0.351500</td>\n","      <td>0.166496</td>\n","      <td>0.100284</td>\n","      <td>0.087268</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.597200</td>\n","      <td>1.577233</td>\n","      <td>0.358500</td>\n","      <td>0.172263</td>\n","      <td>0.119499</td>\n","      <td>0.106427</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>1.589200</td>\n","      <td>1.569896</td>\n","      <td>0.384500</td>\n","      <td>0.188286</td>\n","      <td>0.147094</td>\n","      <td>0.131974</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>1.578100</td>\n","      <td>1.563704</td>\n","      <td>0.390500</td>\n","      <td>0.202263</td>\n","      <td>0.128662</td>\n","      <td>0.156108</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>1.574900</td>\n","      <td>1.564147</td>\n","      <td>0.378000</td>\n","      <td>0.182689</td>\n","      <td>0.163678</td>\n","      <td>0.118418</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>1.572600</td>\n","      <td>1.553932</td>\n","      <td>0.422000</td>\n","      <td>0.209953</td>\n","      <td>0.165296</td>\n","      <td>0.157326</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>1.573300</td>\n","      <td>1.553407</td>\n","      <td>0.416000</td>\n","      <td>0.205985</td>\n","      <td>0.171795</td>\n","      <td>0.152590</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>1.561900</td>\n","      <td>1.547219</td>\n","      <td>0.425500</td>\n","      <td>0.212074</td>\n","      <td>0.168752</td>\n","      <td>0.160088</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>1.568400</td>\n","      <td>1.543463</td>\n","      <td>0.433500</td>\n","      <td>0.217055</td>\n","      <td>0.168218</td>\n","      <td>0.165598</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>1.565900</td>\n","      <td>1.545428</td>\n","      <td>0.427000</td>\n","      <td>0.212917</td>\n","      <td>0.170859</td>\n","      <td>0.161135</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [32/32 00:08]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["eval_loss: 1.5239\n","eval_Accuracy: 0.4235\n","eval_Recall: 0.2109\n","eval_Precision: 0.1702\n","eval_F1: 0.1589\n","eval_runtime: 9.2131\n","eval_samples_per_second: 217.0830\n","eval_steps_per_second: 3.4730\n","epoch: 10.0000\n","Training time: 1438.34 sec\n","Trainable parameters: 0.02M\n","CUDA memory used: 1334.92MB\n"]}],"source":["pt_config = PromptTuningConfig(\n","    task_type=TaskType.SEQ_CLS,\n","    prompt_tuning_init=\"TEXT\",\n","    prompt_tuning_init_text=\"Classify the emotion in this sentence.\",\n","    num_virtual_tokens=20,\n","    tokenizer_name_or_path=model_name,\n",")\n","\n","pt_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n","pt_model = get_peft_model(pt_model, pt_config)\n","pt_model.print_trainable_parameters()\n","pt_model.to(device)\n","\n","trainer = Trainer(\n","    model=pt_model,\n","    args=args,\n","    train_dataset=dataset[\"train\"],\n","    eval_dataset=dataset[\"validation\"],\n","    processing_class=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n",")\n","\n","train_and_show_results(trainer)"]},{"cell_type":"markdown","id":"8ef02a87","metadata":{"id":"8ef02a87"},"source":["**5. LoRA**"]},{"cell_type":"code","execution_count":18,"id":"f2273541","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"f2273541","executionInfo":{"status":"ok","timestamp":1746187881985,"user_tz":-180,"elapsed":5272677,"user":{"displayName":"Константин Розанов","userId":"17140738066365642382"}},"outputId":"b306641c-b9de-40d7-e7da-720835ed805c"},"outputs":[{"output_type":"stream","name":"stdout","text":["R =  2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"]},{"output_type":"stream","name":"stdout","text":["trainable params: 78,342 || all params: 109,565,196 || trainable%: 0.0715\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [10000/10000 17:18, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Recall</th>\n","      <th>Precision</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.022900</td>\n","      <td>0.831250</td>\n","      <td>0.692500</td>\n","      <td>0.486546</td>\n","      <td>0.564912</td>\n","      <td>0.463246</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.670900</td>\n","      <td>0.568593</td>\n","      <td>0.800000</td>\n","      <td>0.676687</td>\n","      <td>0.813248</td>\n","      <td>0.706475</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.501000</td>\n","      <td>0.406667</td>\n","      <td>0.864500</td>\n","      <td>0.796574</td>\n","      <td>0.860621</td>\n","      <td>0.817945</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.414300</td>\n","      <td>0.363120</td>\n","      <td>0.887000</td>\n","      <td>0.840503</td>\n","      <td>0.872995</td>\n","      <td>0.853895</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.371400</td>\n","      <td>0.283621</td>\n","      <td>0.907500</td>\n","      <td>0.867005</td>\n","      <td>0.893234</td>\n","      <td>0.878671</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.334400</td>\n","      <td>0.255554</td>\n","      <td>0.915000</td>\n","      <td>0.875825</td>\n","      <td>0.896806</td>\n","      <td>0.885486</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.292100</td>\n","      <td>0.245937</td>\n","      <td>0.922000</td>\n","      <td>0.889205</td>\n","      <td>0.900985</td>\n","      <td>0.894240</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.286700</td>\n","      <td>0.237090</td>\n","      <td>0.921500</td>\n","      <td>0.901226</td>\n","      <td>0.893671</td>\n","      <td>0.896931</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.272400</td>\n","      <td>0.234125</td>\n","      <td>0.920500</td>\n","      <td>0.888167</td>\n","      <td>0.894853</td>\n","      <td>0.891086</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.278900</td>\n","      <td>0.230692</td>\n","      <td>0.923500</td>\n","      <td>0.894152</td>\n","      <td>0.899698</td>\n","      <td>0.896359</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [32/32 00:06]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["eval_loss: 0.2305\n","eval_Accuracy: 0.9160\n","eval_Recall: 0.8553\n","eval_Precision: 0.8786\n","eval_F1: 0.8642\n","eval_runtime: 6.9214\n","eval_samples_per_second: 288.9590\n","eval_steps_per_second: 4.6230\n","epoch: 10.0000\n","Training time: 1039.32 sec\n","Trainable parameters: 0.08M\n","CUDA memory used: 1786.06MB\n","\n","R =  4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"]},{"output_type":"stream","name":"stdout","text":["trainable params: 152,070 || all params: 109,638,924 || trainable%: 0.1387\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [10000/10000 17:23, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Recall</th>\n","      <th>Precision</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.023200</td>\n","      <td>0.817579</td>\n","      <td>0.704500</td>\n","      <td>0.531508</td>\n","      <td>0.577121</td>\n","      <td>0.517158</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.630500</td>\n","      <td>0.539259</td>\n","      <td>0.810000</td>\n","      <td>0.692367</td>\n","      <td>0.809127</td>\n","      <td>0.715676</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.471600</td>\n","      <td>0.382202</td>\n","      <td>0.875500</td>\n","      <td>0.817688</td>\n","      <td>0.857730</td>\n","      <td>0.830674</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.391000</td>\n","      <td>0.319898</td>\n","      <td>0.894500</td>\n","      <td>0.858076</td>\n","      <td>0.869006</td>\n","      <td>0.862093</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.342000</td>\n","      <td>0.267661</td>\n","      <td>0.907000</td>\n","      <td>0.872903</td>\n","      <td>0.877982</td>\n","      <td>0.874606</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.303700</td>\n","      <td>0.241609</td>\n","      <td>0.916000</td>\n","      <td>0.880849</td>\n","      <td>0.895269</td>\n","      <td>0.887608</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.268500</td>\n","      <td>0.240214</td>\n","      <td>0.920500</td>\n","      <td>0.885444</td>\n","      <td>0.895499</td>\n","      <td>0.889294</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.257400</td>\n","      <td>0.235974</td>\n","      <td>0.922500</td>\n","      <td>0.904006</td>\n","      <td>0.888561</td>\n","      <td>0.895535</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.255000</td>\n","      <td>0.231833</td>\n","      <td>0.924500</td>\n","      <td>0.899768</td>\n","      <td>0.897019</td>\n","      <td>0.898009</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.243800</td>\n","      <td>0.229395</td>\n","      <td>0.927000</td>\n","      <td>0.904767</td>\n","      <td>0.899592</td>\n","      <td>0.901898</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [32/32 00:06]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["eval_loss: 0.2376\n","eval_Accuracy: 0.9220\n","eval_Recall: 0.8743\n","eval_Precision: 0.8899\n","eval_F1: 0.8796\n","eval_runtime: 6.9077\n","eval_samples_per_second: 289.5310\n","eval_steps_per_second: 4.6330\n","epoch: 10.0000\n","Training time: 1044.36 sec\n","Trainable parameters: 0.15M\n","CUDA memory used: 1784.36MB\n","\n","R =  8\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"]},{"output_type":"stream","name":"stdout","text":["trainable params: 299,526 || all params: 109,786,380 || trainable%: 0.2728\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [10000/10000 17:24, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Recall</th>\n","      <th>Precision</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.002800</td>\n","      <td>0.793938</td>\n","      <td>0.705000</td>\n","      <td>0.520763</td>\n","      <td>0.593392</td>\n","      <td>0.509184</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.621200</td>\n","      <td>0.522613</td>\n","      <td>0.817500</td>\n","      <td>0.699954</td>\n","      <td>0.821436</td>\n","      <td>0.726111</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.461800</td>\n","      <td>0.366882</td>\n","      <td>0.875000</td>\n","      <td>0.801693</td>\n","      <td>0.868239</td>\n","      <td>0.823991</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.376300</td>\n","      <td>0.308729</td>\n","      <td>0.897000</td>\n","      <td>0.849479</td>\n","      <td>0.888764</td>\n","      <td>0.864891</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.332800</td>\n","      <td>0.254524</td>\n","      <td>0.915000</td>\n","      <td>0.879919</td>\n","      <td>0.892776</td>\n","      <td>0.885645</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.291500</td>\n","      <td>0.228422</td>\n","      <td>0.922500</td>\n","      <td>0.888838</td>\n","      <td>0.899297</td>\n","      <td>0.893751</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.260500</td>\n","      <td>0.225807</td>\n","      <td>0.925000</td>\n","      <td>0.889869</td>\n","      <td>0.911254</td>\n","      <td>0.898734</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.252900</td>\n","      <td>0.225534</td>\n","      <td>0.925500</td>\n","      <td>0.901018</td>\n","      <td>0.898106</td>\n","      <td>0.899133</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.247000</td>\n","      <td>0.218480</td>\n","      <td>0.926500</td>\n","      <td>0.895619</td>\n","      <td>0.903457</td>\n","      <td>0.898723</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.237000</td>\n","      <td>0.216913</td>\n","      <td>0.926500</td>\n","      <td>0.896850</td>\n","      <td>0.899321</td>\n","      <td>0.897504</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [32/32 00:06]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["eval_loss: 0.2158\n","eval_Accuracy: 0.9235\n","eval_Recall: 0.8700\n","eval_Precision: 0.8945\n","eval_F1: 0.8797\n","eval_runtime: 6.9332\n","eval_samples_per_second: 288.4680\n","eval_steps_per_second: 4.6150\n","epoch: 10.0000\n","Training time: 1044.96 sec\n","Trainable parameters: 0.30M\n","CUDA memory used: 1785.83MB\n","\n","R =  16\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"]},{"output_type":"stream","name":"stdout","text":["trainable params: 594,438 || all params: 110,081,292 || trainable%: 0.5400\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [10000/10000 17:29, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Recall</th>\n","      <th>Precision</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.012800</td>\n","      <td>0.802148</td>\n","      <td>0.702000</td>\n","      <td>0.517468</td>\n","      <td>0.568944</td>\n","      <td>0.507106</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.607800</td>\n","      <td>0.503655</td>\n","      <td>0.820500</td>\n","      <td>0.711339</td>\n","      <td>0.817975</td>\n","      <td>0.737621</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.453300</td>\n","      <td>0.364199</td>\n","      <td>0.883000</td>\n","      <td>0.830135</td>\n","      <td>0.865911</td>\n","      <td>0.841417</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.370000</td>\n","      <td>0.293962</td>\n","      <td>0.901000</td>\n","      <td>0.866735</td>\n","      <td>0.877146</td>\n","      <td>0.870930</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.324200</td>\n","      <td>0.252691</td>\n","      <td>0.915500</td>\n","      <td>0.882842</td>\n","      <td>0.891816</td>\n","      <td>0.886851</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.290100</td>\n","      <td>0.223058</td>\n","      <td>0.924500</td>\n","      <td>0.885440</td>\n","      <td>0.906051</td>\n","      <td>0.894560</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.258200</td>\n","      <td>0.226110</td>\n","      <td>0.923000</td>\n","      <td>0.884074</td>\n","      <td>0.905121</td>\n","      <td>0.892405</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.247900</td>\n","      <td>0.220680</td>\n","      <td>0.927000</td>\n","      <td>0.903428</td>\n","      <td>0.895543</td>\n","      <td>0.899193</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.243700</td>\n","      <td>0.216180</td>\n","      <td>0.928000</td>\n","      <td>0.899295</td>\n","      <td>0.904457</td>\n","      <td>0.900963</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.230100</td>\n","      <td>0.213702</td>\n","      <td>0.929000</td>\n","      <td>0.902075</td>\n","      <td>0.901856</td>\n","      <td>0.901521</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [32/32 00:06]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["eval_loss: 0.2205\n","eval_Accuracy: 0.9260\n","eval_Recall: 0.8797\n","eval_Precision: 0.8982\n","eval_F1: 0.8868\n","eval_runtime: 6.8845\n","eval_samples_per_second: 290.5080\n","eval_steps_per_second: 4.6480\n","epoch: 10.0000\n","Training time: 1050.12 sec\n","Trainable parameters: 0.59M\n","CUDA memory used: 1791.24MB\n","\n","R =  32\n"]},{"output_type":"stream","name":"stderr","text":["No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"]},{"output_type":"stream","name":"stdout","text":["trainable params: 1,184,262 || all params: 110,671,116 || trainable%: 1.0701\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [10000/10000 17:36, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Recall</th>\n","      <th>Precision</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.993100</td>\n","      <td>0.781931</td>\n","      <td>0.711500</td>\n","      <td>0.530398</td>\n","      <td>0.592225</td>\n","      <td>0.522438</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.603800</td>\n","      <td>0.506970</td>\n","      <td>0.823000</td>\n","      <td>0.715156</td>\n","      <td>0.824947</td>\n","      <td>0.739580</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.447100</td>\n","      <td>0.352985</td>\n","      <td>0.880000</td>\n","      <td>0.812128</td>\n","      <td>0.870329</td>\n","      <td>0.831242</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.364500</td>\n","      <td>0.302454</td>\n","      <td>0.899000</td>\n","      <td>0.850782</td>\n","      <td>0.889358</td>\n","      <td>0.865788</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.320100</td>\n","      <td>0.247632</td>\n","      <td>0.915500</td>\n","      <td>0.879062</td>\n","      <td>0.890407</td>\n","      <td>0.884107</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.283400</td>\n","      <td>0.220870</td>\n","      <td>0.925000</td>\n","      <td>0.889054</td>\n","      <td>0.904471</td>\n","      <td>0.896156</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.250300</td>\n","      <td>0.219385</td>\n","      <td>0.928000</td>\n","      <td>0.889245</td>\n","      <td>0.914645</td>\n","      <td>0.899807</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.245000</td>\n","      <td>0.219204</td>\n","      <td>0.930000</td>\n","      <td>0.903059</td>\n","      <td>0.903367</td>\n","      <td>0.902914</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.239800</td>\n","      <td>0.215959</td>\n","      <td>0.928000</td>\n","      <td>0.895047</td>\n","      <td>0.904061</td>\n","      <td>0.898474</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.228000</td>\n","      <td>0.213497</td>\n","      <td>0.930000</td>\n","      <td>0.898098</td>\n","      <td>0.907337</td>\n","      <td>0.901774</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [32/32 00:06]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["eval_loss: 0.2120\n","eval_Accuracy: 0.9270\n","eval_Recall: 0.8742\n","eval_Precision: 0.9093\n","eval_F1: 0.8877\n","eval_runtime: 6.8926\n","eval_samples_per_second: 290.1640\n","eval_steps_per_second: 4.6430\n","epoch: 10.0000\n","Training time: 1056.81 sec\n","Trainable parameters: 1.18M\n","CUDA memory used: 1797.50MB\n","\n"]}],"source":["for r in [2, 4, 8, 16, 32]:\n","    print(\"R = \", r)\n","    lora_config = LoraConfig(task_type=TaskType.SEQ_CLS, r=r)\n","\n","    lora_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n","    lora_model = get_peft_model(lora_model, lora_config)\n","    lora_model.print_trainable_parameters()\n","\n","    lora_model.to(device)\n","\n","    trainer = Trainer(\n","        model=lora_model,\n","        args=args,\n","        train_dataset=dataset[\"train\"],\n","        eval_dataset=dataset[\"validation\"],\n","        processing_class=tokenizer,\n","        data_collator=data_collator,\n","        compute_metrics=compute_metrics,\n","    )\n","\n","    train_and_show_results(trainer)\n","    print()"]},{"cell_type":"code","execution_count":19,"id":"626e99f3","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"626e99f3","executionInfo":{"status":"ok","timestamp":1746187973941,"user_tz":-180,"elapsed":224,"user":{"displayName":"Константин Розанов","userId":"17140738066365642382"}},"outputId":"8c19d3b4-361b-42b8-b96d-686655c12725"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pandas.io.formats.style.Styler at 0x7a3ed2c76c10>"],"text/html":["<style type=\"text/css\">\n","#T_6a7de_row3_col4, #T_6a7de_row4_col3, #T_6a7de_row4_col5, #T_6a7de_row4_col6 {\n","  background-color: green;\n","}\n","</style>\n","<table id=\"T_6a7de\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th class=\"blank level0\" >&nbsp;</th>\n","      <th id=\"T_6a7de_level0_col0\" class=\"col_heading level0 col0\" >R</th>\n","      <th id=\"T_6a7de_level0_col1\" class=\"col_heading level0 col1\" >Trainable Params (M)</th>\n","      <th id=\"T_6a7de_level0_col2\" class=\"col_heading level0 col2\" >Trainable %</th>\n","      <th id=\"T_6a7de_level0_col3\" class=\"col_heading level0 col3\" >Accuracy</th>\n","      <th id=\"T_6a7de_level0_col4\" class=\"col_heading level0 col4\" >Recall</th>\n","      <th id=\"T_6a7de_level0_col5\" class=\"col_heading level0 col5\" >Precision</th>\n","      <th id=\"T_6a7de_level0_col6\" class=\"col_heading level0 col6\" >F1</th>\n","      <th id=\"T_6a7de_level0_col7\" class=\"col_heading level0 col7\" >Training Time (s)</th>\n","      <th id=\"T_6a7de_level0_col8\" class=\"col_heading level0 col8\" >Eval Time (s)</th>\n","      <th id=\"T_6a7de_level0_col9\" class=\"col_heading level0 col9\" >CUDA Memory (MB)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th id=\"T_6a7de_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n","      <td id=\"T_6a7de_row0_col0\" class=\"data row0 col0\" >2</td>\n","      <td id=\"T_6a7de_row0_col1\" class=\"data row0 col1\" >0.080000</td>\n","      <td id=\"T_6a7de_row0_col2\" class=\"data row0 col2\" >0.071500</td>\n","      <td id=\"T_6a7de_row0_col3\" class=\"data row0 col3\" >0.916000</td>\n","      <td id=\"T_6a7de_row0_col4\" class=\"data row0 col4\" >0.855300</td>\n","      <td id=\"T_6a7de_row0_col5\" class=\"data row0 col5\" >0.878600</td>\n","      <td id=\"T_6a7de_row0_col6\" class=\"data row0 col6\" >0.864200</td>\n","      <td id=\"T_6a7de_row0_col7\" class=\"data row0 col7\" >1039.320000</td>\n","      <td id=\"T_6a7de_row0_col8\" class=\"data row0 col8\" >6.921400</td>\n","      <td id=\"T_6a7de_row0_col9\" class=\"data row0 col9\" >1786.060000</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_6a7de_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n","      <td id=\"T_6a7de_row1_col0\" class=\"data row1 col0\" >4</td>\n","      <td id=\"T_6a7de_row1_col1\" class=\"data row1 col1\" >0.150000</td>\n","      <td id=\"T_6a7de_row1_col2\" class=\"data row1 col2\" >0.138700</td>\n","      <td id=\"T_6a7de_row1_col3\" class=\"data row1 col3\" >0.922000</td>\n","      <td id=\"T_6a7de_row1_col4\" class=\"data row1 col4\" >0.874300</td>\n","      <td id=\"T_6a7de_row1_col5\" class=\"data row1 col5\" >0.889900</td>\n","      <td id=\"T_6a7de_row1_col6\" class=\"data row1 col6\" >0.879600</td>\n","      <td id=\"T_6a7de_row1_col7\" class=\"data row1 col7\" >1044.360000</td>\n","      <td id=\"T_6a7de_row1_col8\" class=\"data row1 col8\" >6.907700</td>\n","      <td id=\"T_6a7de_row1_col9\" class=\"data row1 col9\" >1784.360000</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_6a7de_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n","      <td id=\"T_6a7de_row2_col0\" class=\"data row2 col0\" >8</td>\n","      <td id=\"T_6a7de_row2_col1\" class=\"data row2 col1\" >0.300000</td>\n","      <td id=\"T_6a7de_row2_col2\" class=\"data row2 col2\" >0.272800</td>\n","      <td id=\"T_6a7de_row2_col3\" class=\"data row2 col3\" >0.923500</td>\n","      <td id=\"T_6a7de_row2_col4\" class=\"data row2 col4\" >0.870000</td>\n","      <td id=\"T_6a7de_row2_col5\" class=\"data row2 col5\" >0.894500</td>\n","      <td id=\"T_6a7de_row2_col6\" class=\"data row2 col6\" >0.879700</td>\n","      <td id=\"T_6a7de_row2_col7\" class=\"data row2 col7\" >1044.960000</td>\n","      <td id=\"T_6a7de_row2_col8\" class=\"data row2 col8\" >6.933200</td>\n","      <td id=\"T_6a7de_row2_col9\" class=\"data row2 col9\" >1785.830000</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_6a7de_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n","      <td id=\"T_6a7de_row3_col0\" class=\"data row3 col0\" >16</td>\n","      <td id=\"T_6a7de_row3_col1\" class=\"data row3 col1\" >0.590000</td>\n","      <td id=\"T_6a7de_row3_col2\" class=\"data row3 col2\" >0.540000</td>\n","      <td id=\"T_6a7de_row3_col3\" class=\"data row3 col3\" >0.926000</td>\n","      <td id=\"T_6a7de_row3_col4\" class=\"data row3 col4\" >0.879700</td>\n","      <td id=\"T_6a7de_row3_col5\" class=\"data row3 col5\" >0.898200</td>\n","      <td id=\"T_6a7de_row3_col6\" class=\"data row3 col6\" >0.886800</td>\n","      <td id=\"T_6a7de_row3_col7\" class=\"data row3 col7\" >1050.120000</td>\n","      <td id=\"T_6a7de_row3_col8\" class=\"data row3 col8\" >6.884500</td>\n","      <td id=\"T_6a7de_row3_col9\" class=\"data row3 col9\" >1791.240000</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_6a7de_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n","      <td id=\"T_6a7de_row4_col0\" class=\"data row4 col0\" >32</td>\n","      <td id=\"T_6a7de_row4_col1\" class=\"data row4 col1\" >1.180000</td>\n","      <td id=\"T_6a7de_row4_col2\" class=\"data row4 col2\" >1.070100</td>\n","      <td id=\"T_6a7de_row4_col3\" class=\"data row4 col3\" >0.927000</td>\n","      <td id=\"T_6a7de_row4_col4\" class=\"data row4 col4\" >0.874200</td>\n","      <td id=\"T_6a7de_row4_col5\" class=\"data row4 col5\" >0.909300</td>\n","      <td id=\"T_6a7de_row4_col6\" class=\"data row4 col6\" >0.887700</td>\n","      <td id=\"T_6a7de_row4_col7\" class=\"data row4 col7\" >1056.810000</td>\n","      <td id=\"T_6a7de_row4_col8\" class=\"data row4 col8\" >6.892600</td>\n","      <td id=\"T_6a7de_row4_col9\" class=\"data row4 col9\" >1797.500000</td>\n","    </tr>\n","  </tbody>\n","</table>\n"]},"metadata":{},"execution_count":19}],"source":["data = [\n","    {\n","        \"R\": 2,\n","        \"Trainable Params (M)\": 0.08,\n","        \"Trainable %\": 0.0715,\n","        \"Accuracy\": 0.9160,\n","        \"Recall\": 0.8553,\n","        \"Precision\": 0.8786,\n","        \"F1\": 0.8642,\n","        \"Training Time (s)\": 1039.32,\n","        \"Eval Time (s)\": 6.9214,\n","        \"CUDA Memory (MB)\": 1786.06,\n","    },\n","    {\n","        \"R\": 4,\n","        \"Trainable Params (M)\": 0.15,\n","        \"Trainable %\": 0.1387,\n","        \"Accuracy\": 0.9220,\n","        \"Recall\": 0.8743,\n","        \"Precision\": 0.8899,\n","        \"F1\": 0.8796,\n","        \"Training Time (s)\": 1044.36,\n","        \"Eval Time (s)\": 6.9077,\n","        \"CUDA Memory (MB)\": 1784.36,\n","    },\n","    {\n","        \"R\": 8,\n","        \"Trainable Params (M)\": 0.30,\n","        \"Trainable %\": 0.2728,\n","        \"Accuracy\": 0.9235,\n","        \"Recall\": 0.8700,\n","        \"Precision\": 0.8945,\n","        \"F1\": 0.8797,\n","        \"Training Time (s)\": 1044.96,\n","        \"Eval Time (s)\": 6.9332,\n","        \"CUDA Memory (MB)\": 1785.83,\n","    },\n","    {\n","        \"R\": 16,\n","        \"Trainable Params (M)\": 0.59,\n","        \"Trainable %\": 0.5400,\n","        \"Accuracy\": 0.9260,\n","        \"Recall\": 0.8797,\n","        \"Precision\": 0.8982,\n","        \"F1\":0.8868,\n","        \"Training Time (s)\": 1050.12,\n","        \"Eval Time (s)\": 6.8845,\n","        \"CUDA Memory (MB)\": 1791.24,\n","    },\n","    {\n","        \"R\": 32,\n","        \"Trainable Params (M)\": 1.18,\n","        \"Trainable %\": 1.0701,\n","        \"Accuracy\": 0.9270,\n","        \"Recall\": 0.8742,\n","        \"Precision\": 0.9093,\n","        \"F1\": 0.8877,\n","        \"Training Time (s)\": 1056.81,\n","        \"Eval Time (s)\": 6.8926,\n","        \"CUDA Memory (MB)\": 1797.50,\n","    },\n","]\n","\n","df_lora = pd.DataFrame(data)\n","df_lora = df_lora.style.highlight_max(subset=[\"Accuracy\", \"Recall\", \"Precision\", \"F1\"], color=\"green\")\n","df_lora"]},{"cell_type":"markdown","id":"4c8d3462","metadata":{"id":"4c8d3462"},"source":["Мы видим, что качество постепенно растёт с увеличением r, но незначительно. При R = 32 достигается лучший F1-score = 0.8877, но прирост незначителен по сравнению с 16. То есть в целом, можно было его и не проверять. Использование GPU памяти почти не растёт, что делает LoRA очень экономичным. Даже при R = 32 обучается только 1.07% параметров модели (1.18M из 110M)\n","\n","Вывод такой:\n","- если намважна эффективность - оптимальным можно считать R = 8 или R = 16\n","- если хотим легкий бейзлайн - смело берем R = 2\n","\n"]},{"cell_type":"markdown","id":"ad4eee78","metadata":{"id":"ad4eee78"},"source":["**6. Итоговое сравнение**"]},{"cell_type":"code","execution_count":22,"id":"7b04df34","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"7b04df34","executionInfo":{"status":"ok","timestamp":1746188438465,"user_tz":-180,"elapsed":80,"user":{"displayName":"Константин Розанов","userId":"17140738066365642382"}},"outputId":"bd1604be-12d6-4b78-942f-a29dce76272f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pandas.io.formats.style.Styler at 0x7a3eccd424d0>"],"text/html":["<style type=\"text/css\">\n","#T_8011c_row0_col6, #T_8011c_row1_col3, #T_8011c_row2_col5, #T_8011c_row2_col7, #T_8011c_row4_col1, #T_8011c_row4_col2, #T_8011c_row4_col4 {\n","  background-color: green;\n","}\n","</style>\n","<table id=\"T_8011c\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th class=\"blank level0\" >&nbsp;</th>\n","      <th id=\"T_8011c_level0_col0\" class=\"col_heading level0 col0\" >method</th>\n","      <th id=\"T_8011c_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n","      <th id=\"T_8011c_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n","      <th id=\"T_8011c_level0_col3\" class=\"col_heading level0 col3\" >Precision</th>\n","      <th id=\"T_8011c_level0_col4\" class=\"col_heading level0 col4\" >F1-score</th>\n","      <th id=\"T_8011c_level0_col5\" class=\"col_heading level0 col5\" >trainable_params_M</th>\n","      <th id=\"T_8011c_level0_col6\" class=\"col_heading level0 col6\" >cuda_memory_MB</th>\n","      <th id=\"T_8011c_level0_col7\" class=\"col_heading level0 col7\" >training_time_sec</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th id=\"T_8011c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n","      <td id=\"T_8011c_row0_col0\" class=\"data row0 col0\" >no finetuning</td>\n","      <td id=\"T_8011c_row0_col1\" class=\"data row0 col1\" >0.1510</td>\n","      <td id=\"T_8011c_row0_col2\" class=\"data row0 col2\" >0.1619</td>\n","      <td id=\"T_8011c_row0_col3\" class=\"data row0 col3\" >0.1449</td>\n","      <td id=\"T_8011c_row0_col4\" class=\"data row0 col4\" >0.0729</td>\n","      <td id=\"T_8011c_row0_col5\" class=\"data row0 col5\" >109.4900</td>\n","      <td id=\"T_8011c_row0_col6\" class=\"data row0 col6\" >447.6100</td>\n","      <td id=\"T_8011c_row0_col7\" class=\"data row0 col7\" >nan</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_8011c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n","      <td id=\"T_8011c_row1_col0\" class=\"data row1 col0\" >finetuning</td>\n","      <td id=\"T_8011c_row1_col1\" class=\"data row1 col1\" >0.9265</td>\n","      <td id=\"T_8011c_row1_col2\" class=\"data row1 col2\" >0.8639</td>\n","      <td id=\"T_8011c_row1_col3\" class=\"data row1 col3\" >0.9136</td>\n","      <td id=\"T_8011c_row1_col4\" class=\"data row1 col4\" >0.8830</td>\n","      <td id=\"T_8011c_row1_col5\" class=\"data row1 col5\" >109.4900</td>\n","      <td id=\"T_8011c_row1_col6\" class=\"data row1 col6\" >1333.9900</td>\n","      <td id=\"T_8011c_row1_col7\" class=\"data row1 col7\" >1783.3100</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_8011c_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n","      <td id=\"T_8011c_row2_col0\" class=\"data row2 col0\" >linear probing</td>\n","      <td id=\"T_8011c_row2_col1\" class=\"data row2 col1\" >0.4640</td>\n","      <td id=\"T_8011c_row2_col2\" class=\"data row2 col2\" >0.2389</td>\n","      <td id=\"T_8011c_row2_col3\" class=\"data row2 col3\" >0.1531</td>\n","      <td id=\"T_8011c_row2_col4\" class=\"data row2 col4\" >0.1860</td>\n","      <td id=\"T_8011c_row2_col5\" class=\"data row2 col5\" >0.0000</td>\n","      <td id=\"T_8011c_row2_col6\" class=\"data row2 col6\" >895.9400</td>\n","      <td id=\"T_8011c_row2_col7\" class=\"data row2 col7\" >600.4600</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_8011c_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n","      <td id=\"T_8011c_row3_col0\" class=\"data row3 col0\" >prompt tuning</td>\n","      <td id=\"T_8011c_row3_col1\" class=\"data row3 col1\" >0.4235</td>\n","      <td id=\"T_8011c_row3_col2\" class=\"data row3 col2\" >0.2109</td>\n","      <td id=\"T_8011c_row3_col3\" class=\"data row3 col3\" >0.1702</td>\n","      <td id=\"T_8011c_row3_col4\" class=\"data row3 col4\" >0.1589</td>\n","      <td id=\"T_8011c_row3_col5\" class=\"data row3 col5\" >0.0200</td>\n","      <td id=\"T_8011c_row3_col6\" class=\"data row3 col6\" >1334.9200</td>\n","      <td id=\"T_8011c_row3_col7\" class=\"data row3 col7\" >1438.3400</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_8011c_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n","      <td id=\"T_8011c_row4_col0\" class=\"data row4 col0\" >LoRA_R32</td>\n","      <td id=\"T_8011c_row4_col1\" class=\"data row4 col1\" >0.9270</td>\n","      <td id=\"T_8011c_row4_col2\" class=\"data row4 col2\" >0.8742</td>\n","      <td id=\"T_8011c_row4_col3\" class=\"data row4 col3\" >0.9093</td>\n","      <td id=\"T_8011c_row4_col4\" class=\"data row4 col4\" >0.8877</td>\n","      <td id=\"T_8011c_row4_col5\" class=\"data row4 col5\" >1.1800</td>\n","      <td id=\"T_8011c_row4_col6\" class=\"data row4 col6\" >1797.5000</td>\n","      <td id=\"T_8011c_row4_col7\" class=\"data row4 col7\" >1056.8100</td>\n","    </tr>\n","  </tbody>\n","</table>\n"]},"metadata":{},"execution_count":22}],"source":["data = {\n","    \"method\": [\"no finetuning\", \"finetuning\", \"linear probing\", \"prompt tuning\", \"LoRA_R32\"],\n","    \"Accuracy\": [0.1510, 0.9265, 0.4640, 0.4235, 0.9270],\n","    \"Recall\": [0.1619, 0.8639, 0.2389, 0.2109, 0.8742],\n","    \"Precision\": [0.1449, 0.9136, 0.1531, 0.1702, 0.9093],\n","    \"F1-score\": [0.0729, 0.8830, 0.1860, 0.1589, 0.8877],\n","    \"trainable_params_M\": [109.49, 109.49, 0.00, 0.02, 1.18],\n","    \"cuda_memory_MB\": [447.61, 1333.99, 895.94, 1334.92, 1797.50],\n","    \"training_time_sec\": [None, 1783.31, 600.46, 1438.34, 1056.81],\n","}\n","\n","result_df = pd.DataFrame(data)\n","result_df = (\n","    result_df.style.format(precision=4)\n","    .highlight_max(subset=[\"Accuracy\", \"Recall\", \"Precision\", \"F1-score\"], color=\"green\")\n","    .highlight_min(subset=[\"trainable_params_M\", \"cuda_memory_MB\", \"training_time_sec\"], color=\"green\")\n",")\n","result_df"]},{"cell_type":"markdown","source":["**7. Выводы**\n","\n","- Лучшие показатели у нас вышли на LoRA_R32 - выигрываем по Accuracy, Recall и F1 мере. Немного проигрываем по Precision файнтюнингу, а по времени обучения на втором месте, если не считать no finetuning метод. Единственное, где мы сильно проигрываем - это по используемой памяти.\n","\n","- Fine-tuning тоже неплохой, поставил бы его на второе место, но он ну очень долго обучался, почти в 2 раза дольше Лоры.\n","\n","- Prompt tuning и Linear probing - плохенькие по всем показателям, только промпт тюнинг ещё и обучался долго почему-то.\n","\n","- Ну и конечно, no finetuning дал наихудший результат, разве что по памяти всех выиграл, но он и так понятно почему :)\n"],"metadata":{"id":"qON2btbLbDnu"},"id":"qON2btbLbDnu"},{"cell_type":"code","source":[],"metadata":{"id":"gyrhwJawbHbB"},"id":"gyrhwJawbHbB","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}